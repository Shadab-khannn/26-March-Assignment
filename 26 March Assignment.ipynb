{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a56d26-dd85-480c-8a1d-d576fee49f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de14499c-fe12-4d9b-a8c8-82c71175a75e",
   "metadata": {},
   "source": [
    "ANS-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca2f4c-4ada-4ca0-9029-2ffe90103525",
   "metadata": {},
   "outputs": [],
   "source": [
    "Simple Linear Regression :-\n",
    "\n",
    "Simple Linear Regression establishes the relationship between two variables using a straight line. It attempts to draw a line that comes\n",
    "closest to the data by finding the slope and intercept which define the line and minimize regression errors. Simple linear regression has \n",
    "only one x and one y variable.\n",
    "\n",
    "Multi Linear Regression :-\n",
    "\n",
    "Multiple Linear regressions are based on the assumption that there is a linear relationship between both the dependent and independent \n",
    "variables or Predictor variable and Target variable. It also assumes that there is no major correlation between the independent variables.\n",
    "Multi Linear regressions can be linear and nonlinear. It has one y and two or more x variables or one dependent variable and two or more \n",
    "independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86881144-c263-4043-b9ad-fb529887d8c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cae2b1d-da79-4a89-a7e5-d2629e7aa3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b0c65b-2f59-4bda-9338-211ac892fd5c",
   "metadata": {},
   "source": [
    "ANS-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32efa0c-6cc3-4423-9f17-d84bda934188",
   "metadata": {},
   "outputs": [],
   "source": [
    "The assumptions of linear regression are:\n",
    "\n",
    "1.Linearity: The relationship between the independent and dependent variables is linear.\n",
    "2.Independence: The observations are independent of each other.\n",
    "3.Homoscedasticity: The variance of the residuals is constant across all levels of the independent variable.\n",
    "4.Normality: The residuals are normally distributed.\n",
    "\n",
    "To check whether these assumptions hold in a given dataset, you can use the following methods:\n",
    "\n",
    "1.Linearity: You can check for linearity by evaluating a Residuals vs Fitted plot.\n",
    "2.Independence: Each observation should be independent of one another.\n",
    "3.Homoscedasticity: You can check for homoscedasticity by evaluating a Residuals vs Fitted plot.\n",
    "4.Normality: You can check for normality by evaluating a Normal Q-Q plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c6b2f-4e35-487c-bfb5-39a697a8d384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288efd38-2c54-420d-8243-9a19ee5e3341",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b03acba-f9c2-4290-8ac7-337e8a791087",
   "metadata": {},
   "source": [
    "ANS-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab504cec-c3b2-4030-b4e0-3830c83901ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "In a linear regression model, the slope represents the rate of change of the dependent variable with respect to the independent variable.\n",
    "The intercept represents the value of the dependent variable when the independent variable is zero. For example, if you want to model how \n",
    "the cost of renting a car depends on the number of days, you can use a linear equation with slope and intercept. The slope represents the \n",
    "rate of change of the cost per day, and the intercept represents the fixed fee or deposit.\n",
    "\n",
    "Here’s an example: Suppose you are a real estate agent and you want to predict the price of a house based on its size. You collect data on \n",
    "house prices and sizes in your area and fit a linear regression model to this data. The slope of this model represents how much the price of\n",
    "a house increases for each additional square foot of living space. The intercept represents the price of a house with zero square feet of\n",
    "living space, which is not meaningful in this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d19ff91-21aa-4e8f-8183-074fd6af5e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049f40fd-d287-4d37-81f7-3569a4ee4792",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf4ae6c-0b6e-4388-b49a-64c546e3603c",
   "metadata": {},
   "source": [
    "ANS-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfcf933-548e-463a-92c2-e71a040f1aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gradient descent is an optimization algorithm that is used to minimize the loss function or the cost function in a machine learning model. \n",
    "The algorithm works by iteratively adjusting the parameters of the model in the direction of the steepest decrease in the function. \n",
    "The steepest decrease is determined by calculating the gradient of the function with respect to the parameters. The gradient is a vector\n",
    "that points in the direction of the greatest increase in the function. By taking the negative of this vector, we can move in the direction\n",
    "of the greatest decrease in the function. This process is repeated until a minimum of the function is reached.\n",
    "\n",
    "In machine learning, gradient descent is commonly used to train models and neural networks. Training data helps these models learn over time,\n",
    "and the cost function within gradient descent specifically acts as a barometer, gauging its accuracy with each iteration of parameter updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb397f78-30c6-428c-b2b8-0087b2334955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a550cba1-8295-4b47-bfb0-19db03b482f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b79106-bd80-478e-95f5-b4212a3cb337",
   "metadata": {},
   "source": [
    "ANS-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5175a521-0c40-4b87-8fff-c38351c40347",
   "metadata": {},
   "outputs": [],
   "source": [
    "Simple linear regression is a statistical method that uses a single feature to model a linear relationship with a target variable. \n",
    "Multiple linear regression is a more specific calculation than simple linear regression. It uses multiple features to model a linear\n",
    "relationship with a target variable. Multiple linear regression is often better for more complex relationships requiring more consideration.\n",
    "\n",
    "In simple linear regression, there is only one independent variable impacting the slope of the relationship. In contrast, multiple regression\n",
    "incorporates multiple independent variables. Each independent variable in multiple regression has its own slope coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75071ed8-6269-4c7f-b383-92442a606140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83b8309-370a-4938-8ede-ab7fccbe7751",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787bfb30-d849-47df-80ac-e4f4569b6dc1",
   "metadata": {},
   "source": [
    "ANS-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb8f2f0-a838-4858-9a09-64c8fb5d12fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Multicollinearity is a phenomenon in which two or more independent variables in a multiple regression model are highly linearly related. \n",
    "It can cause problems when you fit the model and interpret the results.\n",
    "\n",
    "The best way to detect collinearity in the linear regression model is the multicollinearity variance inflation factor (VIF), calculated to\n",
    "figure out the standard of tolerance and assess the degree of collinearity. For example, if the VIF is 4, indicating a tolerance of 0.25 or \n",
    "lower, there is a possibility that the phenomenon will occur.\n",
    "\n",
    "There are several ways to address multicollinearity in multiple linear regression. Some of them are:\n",
    "\n",
    "1.Remove one of the correlated variables.\n",
    "2.Combine the correlated variables into one variable.\n",
    "3.Use principal component analysis (PCA) to transform the correlated variables into uncorrelated principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86647dd4-bba5-411c-9c2d-c89e27d31dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb29beb-28bd-4c36-a9ac-668c83759772",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ca26a-0a98-41de-a4d1-14e87c2e444a",
   "metadata": {},
   "source": [
    "ANS-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728e8062-4072-402b-9c71-a0527b25123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Polynomial regression is a type of regression analysis that is used when the relationship between the independent variable x and dependent \n",
    "variable y is not linear. In polynomial regression, the relationship between the independent variable x and dependent variable y is modeled\n",
    "as an nth degree polynomial in x. Linear regression, on the other hand, is used when the relationship between the independent variable x and \n",
    "dependent variable y is linear. In linear regression, the relationship between x and y is modeled as a straight line.\n",
    "\n",
    "In other words, polynomial regression is used when the relationship between x and y cannot be accurately modeled by a straight line. \n",
    "Polynomial regression can be used to model relationships that are curved or have more complex shapes than a straight line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c29052-a7e4-41b4-85f7-7a2d916acf9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d3d388-8008-4a8c-b8d0-b98c3955e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4a4881-9e42-454a-ac7a-aab0f4f7c6f2",
   "metadata": {},
   "source": [
    "ANS-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a43688-9a59-4635-9ea9-6e6ef7deee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Polynomial regression is a special case of multiple linear regression. The relationship between the independent variable x and dependent\n",
    "variable y is modeled as an nth degree polynomial in x. Linear regression cannot be used to fit non-linear data (underfitting). \n",
    "Therefore, we increase the model’s complexity and use Polynomial regression, which fits such data better.\n",
    "\n",
    "The advantages of polynomial regression are that it can fit a wide range of functions and can be used to model non-linear relationships between\n",
    "variables. It can also be used to model interactions between variables.\n",
    "\n",
    "The disadvantages of polynomial regression are that it can be sensitive to outliers and can overfit the data if the degree of the polynomial\n",
    "is too high.\n",
    "\n",
    "Polynomial regression is preferred over linear regression when the relationship between the independent variable x and dependent variable y\n",
    "is non-linear. It is also preferred when there are interactions between variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
